# ğŸ¦ RAG Chatbot con LangChain + FAISS - Sistema de Consultas Inteligentes

Una aplicaciÃ³n web que implementa **RAG (Retrieval-Augmented Generation)** usando **LangChain** y **FAISS** para responder consultas sobre el cuarto retiro de AFP en PerÃº, combinando bÃºsquedas locales con informaciÃ³n especÃ­fica y respuestas contextuales.

## ğŸ› ï¸ TecnologÃ­as Principales

Este proyecto utiliza:
- **LangChain**: Framework para construir aplicaciones con modelos de lenguaje
- **FAISS**: Biblioteca de Facebook AI para bÃºsqueda eficiente de similitud en vectores
- **FastAPI**: Framework web moderno para Python
- **React + TypeScript**: Frontend moderno y type-safe
- **HuggingFace Embeddings**: Modelos de embeddings para representaciÃ³n semÃ¡ntica

## ğŸ§  Â¿QuÃ© es RAG y cÃ³mo funciona en este proyecto?

### Â¿QuÃ© es RAG?
**RAG (Retrieval-Augmented Generation)** es una tÃ©cnica de inteligencia artificial que combina:
1. **Retrieval (RecuperaciÃ³n)**: Busca informaciÃ³n relevante en una base de datos local usando **FAISS** para bÃºsqueda vectorial eficiente
2. **Augmented Generation (GeneraciÃ³n Aumentada)**: Usa esa informaciÃ³n para generar respuestas mÃ¡s precisas y contextuales con **LangChain**

### Â¿CÃ³mo funciona nuestro RAG con LangChain + FAISS?

```mermaid
graph TD
    A[Usuario hace pregunta] --> B[LangChain: Convierte pregunta a embedding]
    B --> C[FAISS: BÃºsqueda de similitud en vectorstore]
    C --> D{Â¿Encuentra informaciÃ³n relevante?}
    D -->|SÃ­| E[LangChain: Combina informaciÃ³n local + contexto]
    D -->|No| F[Busca en internet/OpenAI]
    E --> G[Genera respuesta basada en datos locales]
    F --> H[Genera respuesta con informaciÃ³n externa]
    G --> I[Respuesta al usuario]
    H --> I
```

### Ventajas de nuestro sistema RAG con LangChain + FAISS:
- âœ… **InformaciÃ³n especÃ­fica**: Usa datos oficiales sobre el 4to retiro de AFP en PerÃº
- âœ… **BÃºsqueda eficiente con FAISS**: BÃºsqueda vectorial rÃ¡pida y escalable
- âœ… **Pipeline con LangChain**: Procesamiento de documentos, embeddings y bÃºsqueda semÃ¡ntica
- âœ… **Respuestas contextuales**: Las respuestas estÃ¡n basadas en informaciÃ³n real y actualizada
- âœ… **BÃºsqueda semÃ¡ntica**: Encuentra informaciÃ³n relevante aunque no uses las palabras exactas
- âœ… **Fallback inteligente**: Si no encuentra informaciÃ³n local, puede buscar en internet
- âœ… **Sin dependencia de internet**: Funciona principalmente con datos locales

## ğŸ“‹ Requisitos del Sistema

- **Python 3.8+**
- **Node.js 16+**
- **API Key de OpenAI** (opcional, solo para fallback)
- **8GB RAM mÃ­nimo** (para el modelo de embeddings)

## ğŸ› ï¸ ConfiguraciÃ³n e InstalaciÃ³n

### 1. Clonar el Repositorio
```bash
git clone <tu-repositorio>
cd ai-chatbot
```

### 2. Configurar el Backend

```bash
# Navegar al directorio del backend
cd backend

# Crear y activar entorno virtual
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install fastapi uvicorn langchain langchain-community langchain-huggingface sentence-transformers faiss-cpu openai python-dotenv
```

### 3. Configurar Variables de Entorno

Crear archivo `.env` en el directorio `backend/`:
```env
OPENAI_API_KEY=tu_api_key_aqui_opcional
HOST=localhost
PORT=8000
```

**âš ï¸ IMPORTANTE**: El archivo `.env` estÃ¡ en `.gitignore` por seguridad.

### 4. Procesar los Datos (Crear Vectorstore con LangChain + FAISS)

```bash
# AsegÃºrate de estar en el directorio backend con el venv activado
cd backend
source venv/bin/activate

# Ejecutar el script de ingest para procesar los datos
python ingest.py
```

Este comando:
- Lee el archivo `data/data1.txt` con informaciÃ³n sobre el 4to retiro de AFP
- **LangChain**: Divide el texto en chunks usando `RecursiveCharacterTextSplitter`
- **LangChain**: Crea embeddings usando el modelo `sentence-transformers/all-MiniLM-L6-v2` con `HuggingFaceEmbeddings`
- **FAISS**: Crea y guarda el vectorstore en `vector_store/` para bÃºsqueda eficiente

### 5. Configurar el Frontend

```bash
# Navegar al directorio del frontend
cd frontend

# Instalar dependencias
npm install
```

## ğŸš€ Ejecutar la AplicaciÃ³n

### Terminal 1: Backend (API)
```bash
cd backend
source venv/bin/activate
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Terminal 2: Frontend (Interfaz Web)
```bash
cd frontend
npm run dev
```

### URLs de Acceso:
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **DocumentaciÃ³n API**: http://localhost:8000/docs

## ğŸ” CÃ³mo Funciona la BÃºsqueda con LangChain + FAISS

### 1. BÃºsqueda Local (RAG con LangChain + FAISS)
Cuando haces una pregunta, el sistema:
1. **LangChain**: Convierte tu pregunta en un vector usando embeddings (`HuggingFaceEmbeddings`)
2. **FAISS**: Busca en el vectorstore local los documentos mÃ¡s similares usando bÃºsqueda de similitud vectorial
3. **LangChain**: Combina la informaciÃ³n encontrada para generar una respuesta contextual

### 2. Fallback a Internet
Si no encuentra informaciÃ³n relevante localmente, puede:
- Buscar en internet (si estÃ¡ configurado)
- Usar OpenAI para generar una respuesta general

### Ejemplos de Preguntas que Funcionan Bien:
- "Â¿CuÃ¡ndo puedo retirar mi AFP?"
- "Â¿QuÃ© fechas corresponden a mi DNI que termina en 5?"
- "Â¿CuÃ¡nto dinero puedo retirar?"
- "Â¿CÃ³mo consulto mi AFP?"
- "Â¿CuÃ¡les son las fechas del cronograma?"

## ğŸ”§ Estructura del Proyecto

```
ai-chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # API FastAPI con endpoints RAG
â”‚   â”œâ”€â”€ ingest.py            # Script para procesar datos y crear vectorstore
â”‚   â”œâ”€â”€ config.py            # ConfiguraciÃ³n y variables de entorno
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ data1.txt        # InformaciÃ³n sobre 4to retiro AFP PerÃº
â”‚   â”œâ”€â”€ vector_store/        # Vectorstore generado (no versionar)
â”‚   â”‚   â”œâ”€â”€ index.faiss      # Ãndice FAISS
â”‚   â”‚   â””â”€â”€ index.pkl        # Metadatos
â”‚   â”œâ”€â”€ .env                 # Variables de entorno (no versionado)
â”‚   â””â”€â”€ venv/                # Entorno virtual Python
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx          # Componente principal React
â”‚   â”‚   â””â”€â”€ App.css          # Estilos de la aplicaciÃ³n
â”‚   â”œâ”€â”€ package.json         # Dependencias Node.js
â”‚   â””â”€â”€ vite.config.ts       # ConfiguraciÃ³n Vite
â””â”€â”€ README.md                # Este archivo
```

## ğŸš¨ Troubleshooting

### Problema: "Puerto ya en uso"

#### 1. Encontrar quÃ© proceso estÃ¡ usando el puerto:
```bash
# Para puerto 8000 (backend)
lsof -i :8000

# Para puerto 5173 (frontend)
lsof -i :5173

# Ver todos los puertos en uso
netstat -tulpn | grep LISTEN
```

#### 2. Matar procesos especÃ­ficos:
```bash
# Matar proceso por PID (reemplaza XXXX con el PID real)
kill XXXX

# Matar proceso por puerto (macOS/Linux)
sudo lsof -ti:8000 | xargs kill -9
sudo lsof -ti:5173 | xargs kill -9

# Matar todos los procesos de uvicorn
pkill -f uvicorn

# Matar todos los procesos de node/vite
pkill -f "vite\|node"
```

#### 3. Verificar que los procesos se cerraron:
```bash
# Verificar puerto 8000
lsof -i :8000

# Verificar puerto 5173
lsof -i :5173
```

### Problema: "ModuleNotFoundError: No module named 'langchain_community'"

**SoluciÃ³n:**
```bash
cd backend
source venv/bin/activate
pip install langchain-community
```

### Problema: "Vectorstore no disponible"

**SoluciÃ³n:**
```bash
cd backend
source venv/bin/activate
python ingest.py
```

### Problema: "Error al cargar embeddings"

**SoluciÃ³n:**
```bash
# Reinstalar dependencias de embeddings
pip uninstall sentence-transformers
pip install sentence-transformers
```

### Problema: "LangChainDeprecationWarning: The class HuggingFaceEmbeddings was deprecated"

**SoluciÃ³n:**
```bash
# Instalar el paquete actualizado
pip install -U langchain-huggingface

# El cÃ³digo ya estÃ¡ actualizado para usar:
# from langchain_huggingface import HuggingFaceEmbeddings
# en lugar de:
# from langchain_community.embeddings import HuggingFaceEmbeddings
```

### Problema: "LangChainDeprecationWarning: Importing TextLoader from langchain.document_loaders is deprecated"

**SoluciÃ³n:**
```bash
# El cÃ³digo ya estÃ¡ actualizado para usar:
# from langchain_community.document_loaders import TextLoader
# en lugar de:
# from langchain.document_loaders import TextLoader
```

### Problema: Frontend no se conecta al backend

**Verificar:**
1. Backend estÃ¡ corriendo en puerto 8000
2. Frontend estÃ¡ corriendo en puerto 5173
3. No hay errores de CORS (ya configurado en el backend)
4. Verificar en el navegador: http://localhost:8000 (debe mostrar mensaje de bienvenida)

### Comandos de DiagnÃ³stico RÃ¡pido:

```bash
# Verificar que el backend responde
curl http://localhost:8000

# Verificar que el frontend responde
curl http://localhost:5173

# Ver logs del backend
# (Los logs aparecen en la terminal donde ejecutaste uvicorn)

# Ver logs del frontend
# (Los logs aparecen en la terminal donde ejecutaste npm run dev)
```

## ğŸ“Š API Endpoints

### `POST /afp-query`
Consulta sobre el 4to retiro de AFP usando RAG local.

**Request:**
```json
{
  "question": "Â¿CuÃ¡ndo puedo retirar mi AFP si mi DNI termina en 5?"
}
```

**Response:**
```json
{
  "answer": "BasÃ¡ndome en la informaciÃ³n oficial disponible sobre el 4to retiro de AFP en PerÃº:\n\nSi termina en 5: 5, 6 de noviembre o 27 de noviembre...",
  "question": "Â¿CuÃ¡ndo puedo retirar mi AFP si mi DNI termina en 5?",
  "source": "InformaciÃ³n local del archivo data1.txt"
}
```

### `GET /search`
BÃºsqueda directa en el vectorstore.

**Request:**
```
GET /search?query=cronograma%20DNI
```

**Response:**
```json
{
  "results": ["Texto relevante encontrado en los documentos..."]
}
```

## ğŸ¯ Casos de Uso Educativos

Este proyecto es ideal para aprender:

1. **RAG (Retrieval-Augmented Generation)**
2. **LangChain**: Framework completo para aplicaciones con LLMs
   - Document loaders (`TextLoader`)
   - Text splitters (`RecursiveCharacterTextSplitter`)
   - Embeddings (`HuggingFaceEmbeddings`)
   - Vectorstores (`FAISS`)
3. **FAISS**: BÃºsqueda eficiente de similitud en vectores
4. **Embeddings y bÃºsqueda semÃ¡ntica**
5. **Vectorstores con FAISS**
6. **APIs REST con FastAPI**
7. **Frontend con React y TypeScript**
8. **Procesamiento de texto con LangChain**
9. **IntegraciÃ³n de sistemas de IA**

## ğŸ”’ Consideraciones de Seguridad

- âœ… **API Key protegida**: Se almacena en variables de entorno
- âœ… **CORS configurado**: Permite comunicaciÃ³n entre frontend y backend
- âœ… **ValidaciÃ³n de entrada**: Se valida la entrada del usuario
- âœ… **Manejo de errores**: Respuestas de error apropiadas
- âœ… **Datos locales**: No envÃ­a informaciÃ³n sensible a servicios externos

## ğŸ“ PrÃ³ximas Mejoras

- [ ] Agregar mÃ¡s documentos al vectorstore
- [ ] Implementar bÃºsqueda hÃ­brida (local + internet)
- [ ] Agregar mÃ©tricas de calidad de respuestas
- [ ] Implementar cache de respuestas
- [ ] Agregar autenticaciÃ³n de usuarios
- [ ] Mejorar la interfaz de usuario

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

**Desarrollado con â¤ï¸ para enseÃ±ar RAG y sistemas de IA a estudiantes**

*Este proyecto demuestra cÃ³mo implementar un sistema RAG completo con **LangChain** y **FAISS**, desde el procesamiento de datos hasta la interfaz de usuario, usando tecnologÃ­as modernas de IA.*