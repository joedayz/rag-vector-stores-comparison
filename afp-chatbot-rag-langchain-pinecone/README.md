# üè¶ RAG Chatbot con LangChain + Pinecone - Sistema de Consultas Inteligentes

Una aplicaci√≥n web que implementa **RAG (Retrieval-Augmented Generation)** usando **LangChain** y **Pinecone** para responder consultas sobre el cuarto retiro de AFP en Per√∫, combinando b√∫squedas en la nube con informaci√≥n espec√≠fica y respuestas contextuales.

## üõ†Ô∏è Tecnolog√≠as Principales

Este proyecto utiliza:
- **LangChain**: Framework para construir aplicaciones con modelos de lenguaje
- **Pinecone**: Base de datos vectorial en la nube para b√∫squeda eficiente de similitud en vectores
- **FastAPI**: Framework web moderno para Python
- **React + TypeScript**: Frontend moderno y type-safe
- **HuggingFace Embeddings**: Modelos de embeddings para representaci√≥n sem√°ntica

## üß† ¬øQu√© es RAG y c√≥mo funciona en este proyecto?

### ¬øQu√© es RAG?
**RAG (Retrieval-Augmented Generation)** es una t√©cnica de inteligencia artificial que combina:
1. **Retrieval (Recuperaci√≥n)**: Busca informaci√≥n relevante en una base de datos vectorial usando **Pinecone** para b√∫squeda vectorial eficiente en la nube
2. **Augmented Generation (Generaci√≥n Aumentada)**: Usa esa informaci√≥n para generar respuestas m√°s precisas y contextuales con **LangChain**

### ¬øC√≥mo funciona nuestro RAG con LangChain + Pinecone?

```mermaid
graph TD
    A[Usuario hace pregunta] --> B[LangChain: Convierte pregunta a embedding]
    B --> C[Pinecone: B√∫squeda de similitud en vectorstore en la nube]
    C --> D{¬øEncuentra informaci√≥n relevante?}
    D -->|S√≠| E[LangChain: Combina informaci√≥n local + contexto]
    D -->|No| F[Busca en internet/OpenAI]
    E --> G[Genera respuesta basada en datos locales]
    F --> H[Genera respuesta con informaci√≥n externa]
    G --> I[Respuesta al usuario]
    H --> I
```

### Ventajas de nuestro sistema RAG con LangChain + Pinecone:
- ‚úÖ **Informaci√≥n espec√≠fica**: Usa datos oficiales sobre el 4to retiro de AFP en Per√∫
- ‚úÖ **B√∫squeda escalable con Pinecone**: B√∫squeda vectorial r√°pida y escalable en la nube
- ‚úÖ **Pipeline con LangChain**: Procesamiento de documentos, embeddings y b√∫squeda sem√°ntica
- ‚úÖ **Respuestas contextuales**: Las respuestas est√°n basadas en informaci√≥n real y actualizada
- ‚úÖ **B√∫squeda sem√°ntica**: Encuentra informaci√≥n relevante aunque no uses las palabras exactas
- ‚úÖ **Fallback inteligente**: Si no encuentra informaci√≥n local, puede buscar en internet
- ‚úÖ **Almacenamiento en la nube**: Los vectores se almacenan en Pinecone, permitiendo escalabilidad y acceso desde cualquier lugar

## üìã Requisitos del Sistema

- **Python 3.8+**
- **Node.js 16+**
- **API Key de Pinecone** (requerida) - Obt√©n una gratis en [pinecone.io](https://www.pinecone.io/)
- **API Key de OpenAI** (opcional, solo para fallback)
- **8GB RAM m√≠nimo** (para el modelo de embeddings)

## üõ†Ô∏è Configuraci√≥n e Instalaci√≥n

### 1. Clonar el Repositorio

```bash
git clone <tu-repositorio>
cd afp-chatbot-rag-langchain-pinecone
```

### 2. Configurar el Backend

```bash
# Navegar al directorio del backend
cd backend

# Crear y activar entorno virtual
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install fastapi uvicorn langchain langchain-community langchain-huggingface langchain-pinecone sentence-transformers pinecone-client openai python-dotenv
```

### 3. Configurar Variables de Entorno

#### 3.1. Obtener API Key de Pinecone

1. Ve a [pinecone.io](https://www.pinecone.io/) y crea una cuenta gratuita
2. Una vez dentro del dashboard, ve a "API Keys"
3. Copia tu API key (comienza con algo como `pc-...`)
4. Verifica tu regi√≥n/environment en el dashboard (por ejemplo: `us-east-1-aws`, `us-west1-gcp`, `eu-west1-aws`)
   - **Nota**: El c√≥digo autom√°ticamente ajusta el formato de la regi√≥n si es necesario

#### 3.2. Crear archivo `.env`

Crear archivo `.env` en el directorio `backend/`:

```env
# Pinecone (requerido)
PINECONE_API_KEY=tu_api_key_de_pinecone_aqui
PINECONE_ENVIRONMENT=us-east-1-aws
PINECONE_INDEX_NAME=afp-chatbot

# OpenAI (opcional, solo para fallback)
OPENAI_API_KEY=tu_api_key_aqui_opcional

# Servidor
HOST=localhost
PORT=8000
```

**‚ö†Ô∏è IMPORTANTE**: 
- El archivo `.env` est√° en `.gitignore` por seguridad.
- Obt√©n tu API key de Pinecone en [pinecone.io](https://www.pinecone.io/) (cuenta gratuita disponible)
- `PINECONE_ENVIRONMENT` debe coincidir con la regi√≥n de tu proyecto en Pinecone (verifica en tu dashboard)
- `PINECONE_INDEX_NAME` es el nombre del √≠ndice que se crear√°/usar√° en Pinecone

#### 3.3. Validar Configuraci√≥n

Antes de continuar, valida que tu configuraci√≥n sea correcta:

```bash
cd backend
source venv/bin/activate
python validate_pinecone.py
```

Este script verificar√°:
- ‚úÖ Que la API key est√© configurada
- ‚úÖ Que puedas conectarte a Pinecone
- ‚úÖ Si el √≠ndice existe o necesita ser creado

### 4. Procesar los Datos (Crear Vectorstore con LangChain + Pinecone)

```bash
# Aseg√∫rate de estar en el directorio backend con el venv activado
cd backend
source venv/bin/activate

# Ejecutar el script de ingest para procesar los datos
python ingest.py
```

Este comando:
- Lee el archivo `data/data1.txt` con informaci√≥n sobre el 4to retiro de AFP
- **LangChain**: Divide el texto en chunks usando `RecursiveCharacterTextSplitter`
- **LangChain**: Crea embeddings usando el modelo `sentence-transformers/all-MiniLM-L6-v2` con `HuggingFaceEmbeddings`
- **Pinecone**: Crea un √≠ndice en Pinecone (si no existe) y sube los vectores a la nube para b√∫squeda eficiente

**Nota**: 
- La primera vez que ejecutes `ingest.py`, se crear√° autom√°ticamente el √≠ndice en Pinecone
- Si el √≠ndice ya existe, se agregar√°n los nuevos documentos al √≠ndice existente
- El proceso puede tardar unos minutos dependiendo de la cantidad de datos

### 5. Configurar el Frontend

```bash
# Navegar al directorio del frontend
cd frontend

# Instalar dependencias
npm install
```

## üöÄ Ejecutar la Aplicaci√≥n

### Terminal 1: Backend (API)

```bash
cd backend
source venv/bin/activate
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Terminal 2: Frontend (Interfaz Web)

```bash
cd frontend
npm run dev
```

### URLs de Acceso:
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **Documentaci√≥n API**: http://localhost:8000/docs

## üîç C√≥mo Funciona la B√∫squeda con LangChain + Pinecone

### 1. B√∫squeda en la Nube (RAG con LangChain + Pinecone)
Cuando haces una pregunta, el sistema:
1. **LangChain**: Convierte tu pregunta en un vector usando embeddings (`HuggingFaceEmbeddings`)
2. **Pinecone**: Busca en el vectorstore en la nube los documentos m√°s similares usando b√∫squeda de similitud vectorial
3. **LangChain**: Combina la informaci√≥n encontrada para generar una respuesta contextual

### 2. Fallback a Internet
Si no encuentra informaci√≥n relevante localmente, puede:
- Buscar en internet (si est√° configurado)
- Usar OpenAI para generar una respuesta general

### Ejemplos de Preguntas que Funcionan Bien:
- "¬øCu√°ndo puedo retirar mi AFP?"
- "¬øQu√© fechas corresponden a mi DNI que termina en 5?"
- "¬øCu√°nto dinero puedo retirar?"
- "¬øC√≥mo consulto mi AFP?"
- "¬øCu√°les son las fechas del cronograma?"

## üîß Estructura del Proyecto

```
afp-chatbot-rag-langchain-pinecone/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # API FastAPI con endpoints RAG usando Pinecone
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py            # Script para procesar datos y crear vectorstore en Pinecone
‚îÇ   ‚îú‚îÄ‚îÄ validate_pinecone.py # Script de validaci√≥n de configuraci√≥n de Pinecone
‚îÇ   ‚îú‚îÄ‚îÄ diagnose.py          # Script de diagn√≥stico para probar b√∫squedas en Pinecone
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuraci√≥n y variables de entorno
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data1.txt        # Informaci√≥n sobre 4to retiro AFP Per√∫
‚îÇ   ‚îú‚îÄ‚îÄ .env                 # Variables de entorno (no versionado)
‚îÇ   ‚îî‚îÄ‚îÄ venv/                # Entorno virtual Python
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx          # Componente principal React
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.css          # Estilos de la aplicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ package.json         # Dependencias Node.js
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.ts       # Configuraci√≥n Vite
‚îú‚îÄ‚îÄ README.md                # Este archivo
‚îú‚îÄ‚îÄ SETUP_PINECONE.md        # Gu√≠a r√°pida de configuraci√≥n con Pinecone
‚îî‚îÄ‚îÄ SETUP_INSTRUCTIONS.md    # Instrucciones detalladas de configuraci√≥n
```

## üö® Troubleshooting

### Problema: "Puerto ya en uso"

#### 1. Encontrar qu√© proceso est√° usando el puerto:
```bash
# Para puerto 8000 (backend)
lsof -i :8000

# Para puerto 5173 (frontend)
lsof -i :5173

# Ver todos los puertos en uso
netstat -tulpn | grep LISTEN
```

#### 2. Matar procesos espec√≠ficos:
```bash
# Matar proceso por PID (reemplaza XXXX con el PID real)
kill XXXX

# Matar proceso por puerto (macOS/Linux)
sudo lsof -ti:8000 | xargs kill -9
sudo lsof -ti:5173 | xargs kill -9

# Matar todos los procesos de uvicorn
pkill -f uvicorn

# Matar todos los procesos de node/vite
pkill -f "vite\|node"
```

#### 3. Verificar que los procesos se cerraron:
```bash
# Verificar puerto 8000
lsof -i :8000

# Verificar puerto 5173
lsof -i :5173
```

### Problema: "ModuleNotFoundError: No module named 'langchain_pinecone'"

**Soluci√≥n:**
```bash
cd backend
source venv/bin/activate
pip install langchain-pinecone
```

### Problema: "PINECONE_API_KEY no est√° configurada"

**Soluci√≥n:**
1. Obt√©n tu API key de Pinecone en [pinecone.io](https://www.pinecone.io/)
2. Agrega `PINECONE_API_KEY=tu_api_key` al archivo `.env` en `backend/`
3. Ejecuta `python validate_pinecone.py` para verificar la configuraci√≥n

### Problema: "Vectorstore no disponible" o "No se pudo conectar a Pinecone"

**Soluci√≥n:**
1. Ejecuta el script de validaci√≥n primero:
   ```bash
   cd backend
   source venv/bin/activate
   python validate_pinecone.py
   ```
2. Verifica que tu API key de Pinecone sea correcta
3. Verifica que el √≠ndice existe en Pinecone (ejecuta `python ingest.py` si no lo has hecho)
4. Verifica tu conexi√≥n a internet
5. Revisa los logs del backend para m√°s detalles
6. Verifica que `PINECONE_ENVIRONMENT` coincida con tu regi√≥n en Pinecone

### Problema: "Error al crear √≠ndice en Pinecone"

**Soluci√≥n:**
- Verifica que tu cuenta de Pinecone tenga permisos para crear √≠ndices
- Verifica que el nombre del √≠ndice no est√© en uso
- Revisa que `PINECONE_ENVIRONMENT` sea correcto (debe coincidir con tu regi√≥n en Pinecone)

### Problema: "Error al cargar embeddings"

**Soluci√≥n:**
```bash
# Reinstalar dependencias de embeddings
pip uninstall sentence-transformers
pip install sentence-transformers
```

### Problema: "LangChainDeprecationWarning: The class HuggingFaceEmbeddings was deprecated"

**Soluci√≥n:**
```bash
# Instalar el paquete actualizado
pip install -U langchain-huggingface

# El c√≥digo ya est√° actualizado para usar:
# from langchain_huggingface import HuggingFaceEmbeddings
# en lugar de:
# from langchain_community.embeddings import HuggingFaceEmbeddings
```

### Problema: "LangChainDeprecationWarning: Importing TextLoader from langchain.document_loaders is deprecated"

**Soluci√≥n:**
```bash
# El c√≥digo ya est√° actualizado para usar:
# from langchain_community.document_loaders import TextLoader
# en lugar de:
# from langchain.document_loaders import TextLoader
```

### Problema: Frontend no se conecta al backend

**Verificar:**
1. Backend est√° corriendo en puerto 8000
2. Frontend est√° corriendo en puerto 5173
3. No hay errores de CORS (ya configurado en el backend)
4. Verificar en el navegador: http://localhost:8000 (debe mostrar mensaje de bienvenida)

### Comandos de Diagn√≥stico R√°pido:

```bash
# Verificar que el backend responde
curl http://localhost:8000

# Verificar que el frontend responde
curl http://localhost:5173

# Validar configuraci√≥n de Pinecone
cd backend
source venv/bin/activate
python validate_pinecone.py

# Probar b√∫squedas en Pinecone (diagn√≥stico)
cd backend
source venv/bin/activate
python diagnose.py

# Ver logs del backend
# (Los logs aparecen en la terminal donde ejecutaste uvicorn)

# Ver logs del frontend
# (Los logs aparecen en la terminal donde ejecutaste npm run dev)
```

## üìä API Endpoints

### `POST /afp-query`
Consulta sobre el 4to retiro de AFP usando RAG con Pinecone.

**Request:**
```json
{
  "question": "¬øCu√°ndo puedo retirar mi AFP si mi DNI termina en 5?"
}
```

**Response:**
```json
{
  "answer": "Bas√°ndome en la informaci√≥n oficial disponible sobre el 4to retiro de AFP en Per√∫:\n\nSi termina en 5: 5, 6 de noviembre o 27 de noviembre...",
  "question": "¬øCu√°ndo puedo retirar mi AFP si mi DNI termina en 5?",
  "source": "Informaci√≥n local del archivo data1.txt"
}
```

### `GET /search`
B√∫squeda directa en el vectorstore de Pinecone.

**Request:**
```
GET /search?query=cronograma%20DNI
```

**Response:**
```json
{
  "results": ["Texto relevante encontrado en los documentos..."]
}
```

## üéØ Casos de Uso Educativos

Este proyecto es ideal para aprender:

1. **RAG (Retrieval-Augmented Generation)**
2. **LangChain**: Framework completo para aplicaciones con LLMs
   - Document loaders (`TextLoader`)
   - Text splitters (`RecursiveCharacterTextSplitter`)
   - Embeddings (`HuggingFaceEmbeddings`)
   - Vectorstores (`PineconeVectorStore`)
3. **Pinecone**: Base de datos vectorial en la nube para b√∫squeda eficiente
4. **Embeddings y b√∫squeda sem√°ntica**
5. **Vectorstores en la nube con Pinecone**
6. **APIs REST con FastAPI**
7. **Frontend con React y TypeScript**
8. **Procesamiento de texto con LangChain**
9. **Integraci√≥n de sistemas de IA**

## üîí Consideraciones de Seguridad

- ‚úÖ **API Keys protegidas**: Se almacenan en variables de entorno
- ‚úÖ **CORS configurado**: Permite comunicaci√≥n entre frontend y backend
- ‚úÖ **Validaci√≥n de entrada**: Se valida la entrada del usuario
- ‚úÖ **Manejo de errores**: Respuestas de error apropiadas
- ‚úÖ **Datos en la nube**: Los vectores se almacenan de forma segura en Pinecone

## üìù Pr√≥ximas Mejoras

- [ ] Agregar m√°s documentos al vectorstore
- [ ] Implementar b√∫squeda h√≠brida (Pinecone + internet)
- [ ] Agregar m√©tricas de calidad de respuestas
- [ ] Implementar cache de respuestas
- [ ] Agregar autenticaci√≥n de usuarios
- [ ] Mejorar la interfaz de usuario
- [ ] Agregar filtros de metadatos en Pinecone

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

---

**Desarrollado con ‚ù§Ô∏è para ense√±ar RAG y sistemas de IA a estudiantes**

*Este proyecto demuestra c√≥mo implementar un sistema RAG completo con **LangChain** y **Pinecone**, desde el procesamiento de datos hasta la interfaz de usuario, usando tecnolog√≠as modernas de IA y almacenamiento vectorial en la nube.*
