# üè¶ RAG Chatbot con LangChain + Weaviate - Sistema de Consultas Inteligentes

Una aplicaci√≥n web que implementa **RAG (Retrieval-Augmented Generation)** usando **LangChain** y **Weaviate** para responder consultas sobre el cuarto retiro de AFP en Per√∫, combinando b√∫squedas vectoriales con informaci√≥n espec√≠fica y respuestas contextuales.

## üõ†Ô∏è Tecnolog√≠as Principales

Este proyecto utiliza:
- **LangChain**: Framework para construir aplicaciones con modelos de lenguaje
- **Weaviate**: Base de datos vectorial open-source para b√∫squeda eficiente de similitud en vectores (puede usarse localmente o en la nube)
- **FastAPI**: Framework web moderno para Python
- **React + TypeScript**: Frontend moderno y type-safe
- **HuggingFace Embeddings**: Modelos de embeddings para representaci√≥n sem√°ntica

## üß† ¬øQu√© es RAG y c√≥mo funciona en este proyecto?

### ¬øQu√© es RAG?
**RAG (Retrieval-Augmented Generation)** es una t√©cnica de inteligencia artificial que combina:
1. **Retrieval (Recuperaci√≥n)**: Busca informaci√≥n relevante en una base de datos vectorial usando **Weaviate** para b√∫squeda vectorial eficiente
2. **Augmented Generation (Generaci√≥n Aumentada)**: Usa esa informaci√≥n para generar respuestas m√°s precisas y contextuales con **LangChain**

### ¬øC√≥mo funciona nuestro RAG con LangChain + Weaviate?

```mermaid
graph TD
    A[Usuario hace pregunta] --> B[LangChain: Convierte pregunta a embedding]
    B --> C[Weaviate: B√∫squeda de similitud en vectorstore]
    C --> D{¬øEncuentra informaci√≥n relevante?}
    D -->|S√≠| E[LangChain: Combina informaci√≥n local + contexto]
    D -->|No| F[Busca en internet/OpenAI]
    E --> G[Genera respuesta basada en datos locales]
    F --> H[Genera respuesta con informaci√≥n externa]
    G --> I[Respuesta al usuario]
    H --> I
```

### Ventajas de nuestro sistema RAG con LangChain + Weaviate:
- ‚úÖ **Informaci√≥n espec√≠fica**: Usa datos oficiales sobre el 4to retiro de AFP en Per√∫
- ‚úÖ **B√∫squeda escalable con Weaviate**: B√∫squeda vectorial r√°pida y escalable (local o en la nube)
- ‚úÖ **Pipeline con LangChain**: Procesamiento de documentos, embeddings y b√∫squeda sem√°ntica
- ‚úÖ **Respuestas contextuales**: Las respuestas est√°n basadas en informaci√≥n real y actualizada
- ‚úÖ **B√∫squeda sem√°ntica**: Encuentra informaci√≥n relevante aunque no uses las palabras exactas
- ‚úÖ **Fallback inteligente**: Si no encuentra informaci√≥n local, puede buscar en internet
- ‚úÖ **Flexibilidad**: Puedes usar Weaviate localmente (con Docker) o en la nube (Weaviate Cloud)
- ‚úÖ **Open Source**: Weaviate es open-source y gratuito para uso local

## üìã Requisitos del Sistema

- **Python 3.8+**
- **Node.js 16+**
- **Weaviate** (puede usarse localmente con Docker o en la nube con Weaviate Cloud)
  - **Opci√≥n Local**: Docker instalado para ejecutar Weaviate localmente
  - **Opci√≥n Cloud**: Cuenta en [Weaviate Cloud](https://cloud.weaviate.io/) (opcional)
- **API Key de OpenAI** (opcional, solo para fallback)
- **8GB RAM m√≠nimo** (para el modelo de embeddings)

## üõ†Ô∏è Configuraci√≥n e Instalaci√≥n

### 1. Clonar el Repositorio

```bash
git clone <tu-repositorio>
cd afp-chatbot-rag-langchain-pinecone
```

### 2. Configurar el Backend

```bash
# Navegar al directorio del backend
cd backend

# Crear y activar entorno virtual
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install fastapi uvicorn langchain langchain-community langchain-huggingface langchain-weaviate sentence-transformers weaviate-client openai python-dotenv
```

### 3. Configurar Variables de Entorno

#### 3.1. Configurar Weaviate

Tienes dos opciones para usar Weaviate:

**Opci√≥n A: Weaviate Local (Recomendado para desarrollo)**
1. Aseg√∫rate de tener Docker instalado
2. Ejecuta Weaviate localmente:
   ```bash
   docker run -d -p 8080:8080 semitechnologies/weaviate:latest
   ```
3. Verifica que est√© corriendo:
   ```bash
   curl http://localhost:8080/v1/.well-known/ready
   ```

**Opci√≥n B: Weaviate Cloud (Para producci√≥n)**
1. Ve a [cloud.weaviate.io](https://cloud.weaviate.io/) y crea una cuenta
2. Crea un cluster y obt√©n la URL (formato: `https://cluster-id.weaviate.network`)
3. Obt√©n tu API key desde el dashboard

#### 3.2. Crear archivo `.env`

Crear archivo `.env` en el directorio `backend/`:

**Para Weaviate Local:**
```env
# Weaviate Local
WEAVIATE_URL=http://localhost:8080
WEAVIATE_INDEX_NAME=AFP_Chatbot

# OpenAI (opcional, solo para fallback)
OPENAI_API_KEY=tu_api_key_aqui_opcional

# Servidor
HOST=localhost
PORT=8000
```

**Para Weaviate Cloud:**
```env
# Weaviate Cloud
WEAVIATE_URL=https://tu-cluster-id.weaviate.network
WEAVIATE_API_KEY=tu_api_key_de_weaviate_cloud
WEAVIATE_INDEX_NAME=AFP_Chatbot

# OpenAI (opcional, solo para fallback)
OPENAI_API_KEY=tu_api_key_aqui_opcional

# Servidor
HOST=localhost
PORT=8000
```

**‚ö†Ô∏è IMPORTANTE**: 
- El archivo `.env` est√° en `.gitignore` por seguridad.
- Para desarrollo local, usa Weaviate con Docker (gratis y sin l√≠mites)
- Para producci√≥n, considera usar Weaviate Cloud
- `WEAVIATE_INDEX_NAME` es el nombre de la clase que se crear√°/usar√° en Weaviate

#### 3.3. Validar Configuraci√≥n

Antes de continuar, valida que tu configuraci√≥n sea correcta:

```bash
cd backend
source venv/bin/activate
python validate_weaviate.py
```

Este script verificar√°:
- ‚úÖ Que la URL de Weaviate est√© configurada
- ‚úÖ Que puedas conectarte a Weaviate
- ‚úÖ Si la clase existe o necesita ser creada

### 4. Procesar los Datos (Crear Vectorstore con LangChain + Pinecone)

```bash
# Aseg√∫rate de estar en el directorio backend con el venv activado
cd backend
source venv/bin/activate

# Ejecutar el script de ingest para procesar los datos
python ingest.py
```

Este comando:
- Lee el archivo `data/data1.txt` con informaci√≥n sobre el 4to retiro de AFP
- **LangChain**: Divide el texto en chunks usando `RecursiveCharacterTextSplitter`
- **LangChain**: Crea embeddings usando el modelo `sentence-transformers/all-MiniLM-L6-v2` con `HuggingFaceEmbeddings`
- **Weaviate**: Crea una clase en Weaviate (si no existe) y sube los vectores para b√∫squeda eficiente

**Nota**: 
- La primera vez que ejecutes `ingest.py`, se crear√° autom√°ticamente la clase en Weaviate
- Si la clase ya existe, se agregar√°n los nuevos documentos a la clase existente
- El proceso puede tardar unos minutos dependiendo de la cantidad de datos
- Aseg√∫rate de que Weaviate est√© corriendo antes de ejecutar este script

### 5. Configurar el Frontend

```bash
# Navegar al directorio del frontend
cd frontend

# Instalar dependencias
npm install
```

## üöÄ Ejecutar la Aplicaci√≥n

### Terminal 1: Backend (API)

```bash
cd backend
source venv/bin/activate
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Terminal 2: Frontend (Interfaz Web)

```bash
cd frontend
npm run dev
```

### URLs de Acceso:
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **Documentaci√≥n API**: http://localhost:8000/docs

## üîç C√≥mo Funciona la B√∫squeda con LangChain + Weaviate

### 1. B√∫squeda Vectorial (RAG con LangChain + Weaviate)
Cuando haces una pregunta, el sistema:
1. **LangChain**: Convierte tu pregunta en un vector usando embeddings (`HuggingFaceEmbeddings`)
2. **Weaviate**: Busca en el vectorstore los documentos m√°s similares usando b√∫squeda de similitud vectorial
3. **LangChain**: Combina la informaci√≥n encontrada para generar una respuesta contextual

### 2. Fallback a Internet
Si no encuentra informaci√≥n relevante localmente, puede:
- Buscar en internet (si est√° configurado)
- Usar OpenAI para generar una respuesta general

### Ejemplos de Preguntas que Funcionan Bien:
- "¬øCu√°ndo puedo retirar mi AFP?"
- "¬øQu√© fechas corresponden a mi DNI que termina en 5?"
- "¬øCu√°nto dinero puedo retirar?"
- "¬øC√≥mo consulto mi AFP?"
- "¬øCu√°les son las fechas del cronograma?"

## üîß Estructura del Proyecto

```
afp-chatbot-rag-langchain-weaviate/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # API FastAPI con endpoints RAG usando Weaviate
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py            # Script para procesar datos y crear vectorstore en Weaviate
‚îÇ   ‚îú‚îÄ‚îÄ validate_weaviate.py # Script de validaci√≥n de configuraci√≥n de Weaviate
‚îÇ   ‚îú‚îÄ‚îÄ diagnose.py          # Script de diagn√≥stico para probar b√∫squedas en Weaviate
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuraci√≥n y variables de entorno
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data1.txt        # Informaci√≥n sobre 4to retiro AFP Per√∫
‚îÇ   ‚îú‚îÄ‚îÄ .env                 # Variables de entorno (no versionado)
‚îÇ   ‚îî‚îÄ‚îÄ venv/                # Entorno virtual Python
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx          # Componente principal React
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.css          # Estilos de la aplicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ package.json         # Dependencias Node.js
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.ts       # Configuraci√≥n Vite
‚îú‚îÄ‚îÄ README.md                # Este archivo
‚îî‚îÄ‚îÄ SETUP_INSTRUCTIONS.md    # Instrucciones detalladas de configuraci√≥n
```

## üö® Troubleshooting

### Problema: "Puerto ya en uso"

#### 1. Encontrar qu√© proceso est√° usando el puerto:
```bash
# Para puerto 8000 (backend)
lsof -i :8000

# Para puerto 5173 (frontend)
lsof -i :5173

# Ver todos los puertos en uso
netstat -tulpn | grep LISTEN
```

#### 2. Matar procesos espec√≠ficos:
```bash
# Matar proceso por PID (reemplaza XXXX con el PID real)
kill XXXX

# Matar proceso por puerto (macOS/Linux)
sudo lsof -ti:8000 | xargs kill -9
sudo lsof -ti:5173 | xargs kill -9

# Matar todos los procesos de uvicorn
pkill -f uvicorn

# Matar todos los procesos de node/vite
pkill -f "vite\|node"
```

#### 3. Verificar que los procesos se cerraron:
```bash
# Verificar puerto 8000
lsof -i :8000

# Verificar puerto 5173
lsof -i :5173
```

### Problema: "ModuleNotFoundError: No module named 'langchain_weaviate'"

**Soluci√≥n:**
```bash
cd backend
source venv/bin/activate
pip install langchain-weaviate weaviate-client
```

### Problema: "WEAVIATE_URL no est√° configurada"

**Soluci√≥n:**
1. Para Weaviate local: Aseg√∫rate de tener Docker corriendo y ejecuta:
   ```bash
   docker run -d -p 8080:8080 semitechnologies/weaviate:latest
   ```
2. Agrega `WEAVIATE_URL=http://localhost:8080` al archivo `.env` en `backend/`
3. Para Weaviate Cloud: Obt√©n tu URL del dashboard y agrega `WEAVIATE_URL` y `WEAVIATE_API_KEY` al `.env`
4. Ejecuta `python validate_weaviate.py` para verificar la configuraci√≥n

### Problema: "Vectorstore no disponible" o "No se pudo conectar a Weaviate"

**Soluci√≥n:**
1. Ejecuta el script de validaci√≥n primero:
   ```bash
   cd backend
   source venv/bin/activate
   python validate_weaviate.py
   ```
2. Para Weaviate local: Verifica que Docker est√© corriendo:
   ```bash
   docker ps | grep weaviate
   ```
   Si no est√° corriendo, in√≠cialo:
   ```bash
   docker run -d -p 8080:8080 semitechnologies/weaviate:latest
   ```
3. Verifica que la URL de Weaviate sea correcta
4. Verifica que la clase existe en Weaviate (ejecuta `python ingest.py` si no lo has hecho)
5. Verifica tu conexi√≥n a internet (si usas Weaviate Cloud)
6. Revisa los logs del backend para m√°s detalles

### Problema: "Error al crear clase en Weaviate"

**Soluci√≥n:**
- Verifica que Weaviate est√© corriendo y accesible
- Verifica que la URL de Weaviate sea correcta
- Para Weaviate Cloud: Verifica que tu API key sea correcta
- Revisa los logs de Weaviate para m√°s detalles

### Problema: "Error al cargar embeddings"

**Soluci√≥n:**
```bash
# Reinstalar dependencias de embeddings
pip uninstall sentence-transformers
pip install sentence-transformers
```

### Problema: "LangChainDeprecationWarning: The class HuggingFaceEmbeddings was deprecated"

**Soluci√≥n:**
```bash
# Instalar el paquete actualizado
pip install -U langchain-huggingface

# El c√≥digo ya est√° actualizado para usar:
# from langchain_huggingface import HuggingFaceEmbeddings
# en lugar de:
# from langchain_community.embeddings import HuggingFaceEmbeddings
```

### Problema: "LangChainDeprecationWarning: Importing TextLoader from langchain.document_loaders is deprecated"

**Soluci√≥n:**
```bash
# El c√≥digo ya est√° actualizado para usar:
# from langchain_community.document_loaders import TextLoader
# en lugar de:
# from langchain.document_loaders import TextLoader
```

### Problema: Frontend no se conecta al backend

**Verificar:**
1. Backend est√° corriendo en puerto 8000
2. Frontend est√° corriendo en puerto 5173
3. No hay errores de CORS (ya configurado en el backend)
4. Verificar en el navegador: http://localhost:8000 (debe mostrar mensaje de bienvenida)

### Comandos de Diagn√≥stico R√°pido:

```bash
# Verificar que el backend responde
curl http://localhost:8000

# Verificar que el frontend responde
curl http://localhost:5173

# Validar configuraci√≥n de Weaviate
cd backend
source venv/bin/activate
python validate_weaviate.py

# Probar b√∫squedas en Weaviate (diagn√≥stico)
cd backend
source venv/bin/activate
python diagnose.py

# Ver logs del backend
# (Los logs aparecen en la terminal donde ejecutaste uvicorn)

# Ver logs del frontend
# (Los logs aparecen en la terminal donde ejecutaste npm run dev)
```

## üìä API Endpoints

### `POST /afp-query`
Consulta sobre el 4to retiro de AFP usando RAG con Weaviate.

**Request:**
```json
{
  "question": "¬øCu√°ndo puedo retirar mi AFP si mi DNI termina en 5?"
}
```

**Response:**
```json
{
  "answer": "Bas√°ndome en la informaci√≥n oficial disponible sobre el 4to retiro de AFP en Per√∫:\n\nSi termina en 5: 5, 6 de noviembre o 27 de noviembre...",
  "question": "¬øCu√°ndo puedo retirar mi AFP si mi DNI termina en 5?",
  "source": "Informaci√≥n local del archivo data1.txt"
}
```

### `GET /search`
B√∫squeda directa en el vectorstore de Weaviate.

**Request:**
```
GET /search?query=cronograma%20DNI
```

**Response:**
```json
{
  "results": ["Texto relevante encontrado en los documentos..."]
}
```

## üéØ Casos de Uso Educativos

Este proyecto es ideal para aprender:

1. **RAG (Retrieval-Augmented Generation)**
2. **LangChain**: Framework completo para aplicaciones con LLMs
   - Document loaders (`TextLoader`)
   - Text splitters (`RecursiveCharacterTextSplitter`)
   - Embeddings (`HuggingFaceEmbeddings`)
   - Vectorstores (`WeaviateVectorStore`)
3. **Weaviate**: Base de datos vectorial open-source para b√∫squeda eficiente
4. **Embeddings y b√∫squeda sem√°ntica**
5. **Vectorstores con Weaviate (local o en la nube)**
6. **APIs REST con FastAPI**
7. **Frontend con React y TypeScript**
8. **Procesamiento de texto con LangChain**
9. **Integraci√≥n de sistemas de IA**
10. **Docker para despliegue local de Weaviate**

## üîí Consideraciones de Seguridad

- ‚úÖ **API Keys protegidas**: Se almacenan en variables de entorno
- ‚úÖ **CORS configurado**: Permite comunicaci√≥n entre frontend y backend
- ‚úÖ **Validaci√≥n de entrada**: Se valida la entrada del usuario
- ‚úÖ **Manejo de errores**: Respuestas de error apropiadas
- ‚úÖ **Datos seguros**: Los vectores se almacenan de forma segura en Weaviate (local o en la nube)

## üìù Pr√≥ximas Mejoras

- [ ] Agregar m√°s documentos al vectorstore
- [ ] Implementar b√∫squeda h√≠brida (Weaviate + internet)
- [ ] Agregar m√©tricas de calidad de respuestas
- [ ] Implementar cache de respuestas
- [ ] Agregar autenticaci√≥n de usuarios
- [ ] Mejorar la interfaz de usuario
- [ ] Agregar filtros de metadatos en Weaviate
- [ ] Implementar b√∫squeda h√≠brida (vectorial + keyword) con Weaviate

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

---

**Desarrollado con ‚ù§Ô∏è para ense√±ar RAG y sistemas de IA a estudiantes**

*Este proyecto demuestra c√≥mo implementar un sistema RAG completo con **LangChain** y **Weaviate**, desde el procesamiento de datos hasta la interfaz de usuario, usando tecnolog√≠as modernas de IA y almacenamiento vectorial open-source.*
